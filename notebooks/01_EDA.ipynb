{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6a31a609",
   "metadata": {},
   "source": [
    "# DREAMLENS AI â€” EDA & Prototype Notebook\n",
    "This notebook walks through loading the dataset, quick EDA, simple preprocessing, and an initial prototype function to map dream texts to dataset interpretations and labels. It follows the development outline described in the project plan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805f27a1",
   "metadata": {
    "vscode": {
     "languageId": "json"
    }
   },
   "outputs": [],
   "source": [
    "# Setup and load dataset\n",
    "\n",
    "This section loads the `project/cleaned_dream_interpretations.csv` dataset and prints a few quick summaries (shape, head, most frequent `Word` values, interpretation lengths).\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell id=\"#VSC-2\" language=\"python\">\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('project') / 'cleaned_dream_interpretations.csv'\n",
    "\n",
    "print('Loading dataset from', DATA_PATH)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "df.head()\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell id=\"#VSC-3\" language=\"python\">\n",
    "print('Shape:', df.shape)\n",
    "print('Columns:', df.columns.tolist())\n",
    "print('\\nTop words:')\n",
    "print(df['Word'].value_counts().head(20))\n",
    "\n",
    "# Distribution of interpretation lengths\n",
    "df['interp_len'] = df['Interpretation'].astype(str).apply(len)\n",
    "print('\\nInterpretation length stats:')\n",
    "print(df['interp_len'].describe())\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell id=\"#VSC-4\" language=\"markdown\">\n",
    "# Simple preprocessing\n",
    "\n",
    "- Lowercase\n",
    "- Drop exact duplicates\n",
    "- Basic tokenization (using whitespace) for quick checks\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell id=\"#VSC-5\" language=\"python\">\n",
    "# Preprocessing\n",
    "import numpy as np\n",
    "\n",
    "df['Word_clean'] = df['Word'].astype(str).str.lower().str.strip()\n",
    "df = df.drop_duplicates(subset=['Word_clean','Interpretation']).reset_index(drop=True)\n",
    "\n",
    "print('After cleaning shape:', df.shape)\n",
    "\n",
    "# Quick token counts for a few examples\n",
    "sample = df['Word_clean'].value_counts().head(30)\n",
    "\n",
    "sample\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell id=\"#VSC-6\" language=\"markdown\">\n",
    "# Prototype: Find matches using TF-IDF\n",
    "\n",
    "Create a small function that uses TF-IDF to find the closest dataset interpretation to a free-form dream text.\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell id=\"#VSC-7\" language=\"python\">\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(df['Word_clean'])\n",
    "\n",
    "\n",
    "def find_best_match(text, top_k=3):\n",
    "    v = vectorizer.transform([text.lower()])\n",
    "    sims = cosine_similarity(v, X).flatten()\n",
    "    top_idx = sims.argsort()[::-1][:top_k]\n",
    "    return df.iloc[top_idx][['Word','Interpretation']].assign(score=sims[top_idx])\n",
    "\n",
    "# Try an example\n",
    "find_best_match('flying over the city and feeling free')\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell id=\"#VSC-8\" language=\"markdown\">\n",
    "# Prototype: Zero-shot labeling + prompt for generation\n",
    "\n",
    "Use Hugging Face zero-shot (BART-MNLI) to suggest short theme labels, then feed prompt into Flan-T5 to generate interpretation text (not executed here if models are not available locally).\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell id=\"#VSC-9\" language=\"python\">\n",
    "try:\n",
    "    from transformers import pipeline, AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "    zsc = pipeline('zero-shot-classification', model='facebook/bart-large-mnli')\n",
    "    zsc('I was being chased', ['fear','stress','freedom'], multi_label=True)\n",
    "except Exception as e:\n",
    "    print('Models not available in this env:', e)\n",
    "\n",
    "# You can run the model steps inside a colab or a machine with sufficient RAM/GPU.\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell id=\"#VSC-10\" language=\"markdown\">\n",
    "# Visualizations\n",
    "\n",
    "Plot top words and basic length distributions (histograms). Use plotly or seaborn for interactivity.\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell id=\"#VSC-11\" language=\"python\">\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10,5))\n",
    "df['interp_len'].hist(bins=40)\n",
    "plt.title('Interpretation length distribution')\n",
    "plt.show()\n",
    "</VSCode.Cell>\n",
    "\n",
    "<VSCode.Cell id=\"#VSC-12\" language=\"markdown\">\n",
    "# Next steps\n",
    "\n",
    "- Add more data cleaning and canonicalization of words\n",
    "- Create a small classification dataset by annotating 500-1k dreams with themes\n",
    "- Prototype a lightweight inference API (already implemented in `DREAMLENS AI/app.py`)\n",
    "- Add unit tests for the matching and label-generation steps\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
